{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO06MSM4pcoSQTPbcpNpr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harish-15112003/MCW_RangeNet/blob/main/RangeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYCG6P9LdOQO",
        "outputId": "17144b8c-bec2-4d37-ce0a-ddead14f8143"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/SemanticKITTI\n",
        "# !cp -r \"/content/drive/MyDrive/dataset/sequences/\" /content/SemanticKITTI/\n"
      ],
      "metadata": {
        "id": "mzdmAxGZdd9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoz3OwEWViYE",
        "outputId": "1c2afd96-eea1-4a93-e02d-1c83edcba66b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lidar-bonnetal'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 109 (delta 0), reused 0 (delta 0), pack-reused 106 (from 1)\u001b[K\n",
            "Receiving objects: 100% (109/109), 17.44 MiB | 16.80 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PRBonn/lidar-bonnetal.git\n",
        "# cd lidar-bonnetal\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd lidar-bonnetal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBxq_HJUVmDr",
        "outputId": "a016f54d-2321-49ad-f98c-3d3290a1577f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lidar-bonnetal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up0RJsv8VmAT",
        "outputId": "bcfcf254-8dc4-4c57-ba61-09f6c12617a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.14.0 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.14.0.zip (4.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/4.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/4.9 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/4.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/4.9 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchvision==0.2.2.post3 (from -r requirements.txt (line 3))\n",
            "  Downloading torchvision-0.2.2.post3-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==2.2.3 (from -r requirements.txt (line 4))\n",
            "  Downloading matplotlib-2.2.3.tar.gz (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.13.1 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.19.0rc0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/dataset/ /content/lidar-bonnetal/train/tasks/semantic/\n"
      ],
      "metadata": {
        "id": "sUNYxnOQ6WOM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/lidar-bonnetal/train/tasks/semantic/infer.py -d /content/lidar-bonnetal/train/tasks/semantic/dataset -m  /content/drive/MyDrive/darknet53\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzu1G-Huq8fF",
        "outputId": "530ced04-e27a-4446-fe5b-74cc9e7b27ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "INTERFACE:\n",
            "dataset /content/lidar-bonnetal/train/tasks/semantic/dataset\n",
            "log /root/logs/2025-3-09-06:55/\n",
            "model /content/drive/MyDrive/darknet53\n",
            "----------\n",
            "\n",
            "Commit hash (training version):  b'99b827f'\n",
            "----------\n",
            "\n",
            "Opening arch config file from /content/drive/MyDrive/darknet53\n",
            "Opening data config file from /content/drive/MyDrive/darknet53\n",
            "train 00\n",
            "train 01\n",
            "train 02\n",
            "train 03\n",
            "train 04\n",
            "train 05\n",
            "train 06\n",
            "train 07\n",
            "train 09\n",
            "train 10\n",
            "valid 08\n",
            "test 11\n",
            "test 12\n",
            "test 13\n",
            "test 14\n",
            "test 15\n",
            "test 16\n",
            "test 17\n",
            "test 18\n",
            "test 19\n",
            "test 20\n",
            "test 21\n",
            "model folder exists! Using model from /content/drive/MyDrive/darknet53\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/lidar-bonnetal/train/tasks/semantic/infer.py\", line 108, in <module>\n",
            "    user = User(ARCH, DATA, FLAGS.dataset, FLAGS.log, FLAGS.model)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/lidar-bonnetal/train/tasks/semantic/modules/user.py\", line 34, in __init__\n",
            "    parserModule = imp.load_source(\"parserModule\",\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/imp.py\", line 172, in load_source\n",
            "    module = _load(spec)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 721, in _load\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1073, in get_code\n",
            "  File \"/usr/lib/python3.11/imp.py\", line 158, in get_data\n",
            "    return super().get_data(path)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1130, in get_data\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/train/tasks/semantic/dataset/kitti/parser.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPtnA8MqrGVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/lidar-bonnetal/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crFQv1fdAFXU",
        "outputId": "8a2509c4-d04a-4eb0-bfab-be4c27e2937e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lidar-bonnetal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assets removed\n",
        "# changed module imports"
      ],
      "metadata": {
        "id": "lxtCjQoMy_6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/lidar-bonnetal/train/tasks/semantic/infer.py -d /content/lidar-bonnetal/train/tasks/semantic/dataset/ -l /content/predictions/ -m   /content/drive/MyDrive/darknet53\n"
      ],
      "metadata": {
        "id": "R3Uwbob5bXmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef3c768-2bcc-44ce-ab96-8ff2e4f63d40"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "INTERFACE:\n",
            "dataset /content/lidar-bonnetal/train/tasks/semantic/dataset/\n",
            "log /content/predictions/\n",
            "model /content/drive/MyDrive/darknet53\n",
            "----------\n",
            "\n",
            "Commit hash (training version):  b'99b827f'\n",
            "----------\n",
            "\n",
            "Opening arch config file from /content/drive/MyDrive/darknet53\n",
            "train 00\n",
            "train 01\n",
            "train 02\n",
            "train 03\n",
            "train 04\n",
            "train 05\n",
            "train 06\n",
            "train 07\n",
            "train 09\n",
            "train 10\n",
            "valid 08\n",
            "test 11\n",
            "test 12\n",
            "test 13\n",
            "test 14\n",
            "test 15\n",
            "test 16\n",
            "test 17\n",
            "test 18\n",
            "test 19\n",
            "test 20\n",
            "test 21\n",
            "model folder exists! Using model from /content/drive/MyDrive/darknet53\n",
            "Sequences folder exists! Using sequences from /content/lidar-bonnetal/train/tasks/semantic/dataset/sequences\n",
            "parsing seq 00\n",
            "parsing seq 01\n",
            "parsing seq 02\n",
            "parsing seq 03\n",
            "parsing seq 04\n",
            "parsing seq 05\n",
            "parsing seq 06\n",
            "parsing seq 07\n",
            "parsing seq 09\n",
            "parsing seq 10\n",
            "Using 0 scans from sequences [0, 1, 2, 3, 4, 5, 6, 7, 9, 10]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Sequences folder exists! Using sequences from /content/lidar-bonnetal/train/tasks/semantic/dataset/sequences\n",
            "parsing seq 08\n",
            "Using 0 scans from sequences [8]\n",
            "Sequences folder exists! Using sequences from /content/lidar-bonnetal/train/tasks/semantic/dataset/sequences\n",
            "parsing seq 11\n",
            "parsing seq 12\n",
            "parsing seq 13\n",
            "parsing seq 14\n",
            "parsing seq 15\n",
            "parsing seq 16\n",
            "parsing seq 17\n",
            "parsing seq 18\n",
            "parsing seq 19\n",
            "parsing seq 20\n",
            "parsing seq 21\n",
            "Using 0 scans from sequences [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
            "Using DarknetNet53 Backbone\n",
            "Depth of backbone input =  5\n",
            "Original OS:  32\n",
            "New OS:  32\n",
            "Strides:  [2, 2, 2, 2, 2]\n",
            "Decoder original OS:  32\n",
            "Decoder new OS:  32\n",
            "Decoder strides:  [2, 2, 2, 2, 2]\n",
            "Total number of parameters:  50377364\n",
            "Total number of parameters requires_grad:  50377364\n",
            "Param encoder  40585504\n",
            "Param decoder  9786080\n",
            "Param head  5780\n",
            "/content/lidar-bonnetal/train/tasks/semantic/modules/segmentator.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  w_dict = torch.load(path + \"/backbone\" + path_append,\n",
            "Successfully loaded model backbone weights\n",
            "/content/lidar-bonnetal/train/tasks/semantic/modules/segmentator.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  w_dict = torch.load(path + \"/segmentation_decoder\" + path_append,\n",
            "Successfully loaded model decoder weights\n",
            "/content/lidar-bonnetal/train/tasks/semantic/modules/segmentator.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  w_dict = torch.load(path + \"/segmentation_head\" + path_append,\n",
            "Successfully loaded model head weights\n",
            "Infering in device:  cpu\n",
            "Finished Infering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/lidar-bonnetal/train/tasks/semantic/evaluate_iou.py -d /content/lidar-bonnetal/train/tasks/semantic/dataset -p /content/predictions/ --split valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBo12HFFx7KC",
        "outputId": "49b4565b-bc29-4676-c040-4131f5705aac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************\n",
            "INTERFACE:\n",
            "Data:  /content/lidar-bonnetal/train/tasks/semantic/dataset\n",
            "Predictions:  /content/predictions/\n",
            "Split:  valid\n",
            "Config:  /content/drive/MyDrive/darknet53/data_cfg.yaml\n",
            "Limit:  None\n",
            "********************************************************************************\n",
            "Opening data config file /content/drive/MyDrive/darknet53/data_cfg.yaml\n",
            "Ignoring xentropy class  0  in IoU evaluation\n",
            "[IOU EVAL] IGNORE:  tensor([0])\n",
            "[IOU EVAL] INCLUDE:  tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "        19])\n",
            "Evaluating sequences: \n",
            "Validation set:\n",
            "Acc avg 0.000\n",
            "IoU avg 0.000\n",
            "IoU class 1 [car] = 0.000\n",
            "IoU class 2 [bicycle] = 0.000\n",
            "IoU class 3 [motorcycle] = 0.000\n",
            "IoU class 4 [truck] = 0.000\n",
            "IoU class 5 [other-vehicle] = 0.000\n",
            "IoU class 6 [person] = 0.000\n",
            "IoU class 7 [bicyclist] = 0.000\n",
            "IoU class 8 [motorcyclist] = 0.000\n",
            "IoU class 9 [road] = 0.000\n",
            "IoU class 10 [parking] = 0.000\n",
            "IoU class 11 [sidewalk] = 0.000\n",
            "IoU class 12 [other-ground] = 0.000\n",
            "IoU class 13 [building] = 0.000\n",
            "IoU class 14 [fence] = 0.000\n",
            "IoU class 15 [vegetation] = 0.000\n",
            "IoU class 16 [trunk] = 0.000\n",
            "IoU class 17 [terrain] = 0.000\n",
            "IoU class 18 [pole] = 0.000\n",
            "IoU class 19 [traffic-sign] = 0.000\n",
            "********************************************************************************\n",
            "below can be copied straight for paper table\n",
            "0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/lidar-bonnetal/train/tasks/semantic/dataset/sequences -type d | wc -l\n"
      ],
      "metadata": {
        "id": "WSfFzDu3Vl51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3d480e-717d-4c91-de28-51b5f4192b0f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -la\n"
      ],
      "metadata": {
        "id": "nx51xxukVlzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64052032-f39b-4b03-b5f5-6c4dee91fcbe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 40\n",
            "drwxr-xr-x 5 root root 4096 Mar  9 06:42 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Mar  9 07:07 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 8 root root 4096 Mar  9 06:42 \u001b[01;34m.git\u001b[0m/\n",
            "-rw-r--r-- 1 root root   81 Mar  9 06:42 .gitignore\n",
            "-rw-r--r-- 1 root root 1160 Mar  9 06:42 LICENSE\n",
            "drwxr-xr-x 2 root root 4096 Mar  9 06:42 \u001b[01;34mpics\u001b[0m/\n",
            "-rw-r--r-- 1 root root 6438 Mar  9 06:42 README.md\n",
            "-rw-r--r-- 1 root root  231 Mar  9 06:42 requirements.txt\n",
            "drwxr-xr-x 6 root root 4096 Mar  9 06:42 \u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g9suVSsFVlv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fit0sK_cVltl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MPf6Yjj-Vlq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhzgs-LIVlmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XimTzW5yVlkP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}